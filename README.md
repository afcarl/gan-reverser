# About

This project introduces a new network to the [GAN](http://papers.nips.cc/paper/5423-generative-adversarial-nets) schema, called the "Reverser" (R).
The Reverser receives images generated by the Generator (G) and tries to reproduce the noise vectors that were initially fed into G.
This seems to have some potential for Unsupervised Learning, as well as fixing errors in the images generated by G.

# Results

## Embedding learned by G

The following images show roughly the low dimensional representation of faces learned by G (R is not used here, yet).
To generate the images, a random noise vector of 32 normal distributed components was first generated.
Then each component of the noise vector was picked (one by one) and set to values between -3.0 and +3.0 (in 16 steps).
That led to `32*16 = 512` noise vectors. For each noise vector one image was generated.

![Varying single components of a noise vector](images/variations.jpg?raw=true "Varying single components of a noise vector")

Apparently G does not connect single features with single components, e.g. one for the gender or the size of the nose.
Instead, changing single components morphs the whole face.

## Sorting by similarity

The following images show some of 10,000 faces that were randomly generated by G.
All faces were reversed to noise vectors using R, resulting in one noise vector per face.
Then for each image one face was picked.
That face's recovered noise vector was compared to all other recovered noise vectors using cosine similarity.
Then the 100 most similar faces were picked.

![Similarity search 1](images/similar_01.jpg?raw=true "Similarity search 1")
![Similarity search 2](images/similar_02.jpg?raw=true "Similarity search 2")
![Similarity search 3](images/similar_03.jpg?raw=true "Similarity search 3")
![Similarity search 4](images/similar_04.jpg?raw=true "Similarity search 4")
![Similarity search 5](images/similar_05.jpg?raw=true "Similarity search 5")

The images indicate that the pair of G and R do have some potential for unsupervised learning.
However, the results are not yet good enough to be used in production.

## Clustering

Just like in the previous section ("Sorting by similarity"), 10000 faces were generated by G.
For each face the noise vector was recovered using R.
These 10,000 noise vectors were then grouped into 20 clusters using kmeans (each image was assigned to its closest cluster centroid).
For each cluster, the average of all faces within the cluster was calculated (add up the pixel values, divide by the count).
Each image shows one cluster with the first face being the average of the cluster.

![Cluster 1](images/cluster_01.jpg?raw=true "Cluster 1")
![Cluster 2](images/cluster_02.jpg?raw=true "Cluster 2")
![Cluster 3](images/cluster_03.jpg?raw=true "Cluster 3")
![Cluster 4](images/cluster_04.jpg?raw=true "Cluster 4")
![Cluster 5](images/cluster_05.jpg?raw=true "Cluster 5")

The clusters do contain faces that have some similarity.
However, the similarity seems to be on a broader level than usually desired.
I.e., the similarity is mostly focused on aspects like brightness, contrast or angle/rotation.
This is probably expected given the (previously described) coarse embedding.

## Fixing errors in generated images

R can be used to fix some errors in images generated by G.
The method for that is simple:
1. Generate an image using a random noise vector,
2. Apply R to the image to recover the noise vector,
3. Feed the recovered noise vector back into G to generate a new image.

The new image tends to be a regression to the mean, i.e. many errors are fixed and some characteristic details get lost or are replaced by more common details.
The error fixing effect seems to be more prominent, making this process useful.
Note that R usually does not fix catastrophic failures of G (e.g. mostly white/black images, completely distorted faces).

The following image shows faces before (left) and after (right) fixing.

![Images before and after R](images/fixed_images.jpg?raw=true "Images before and after R")

This method might be usable for anomaly detection: Fix an image and compare its unfixed and fixed version with each other.
If they are too dissimilar, the image may be considered an anomaly.


# Usage

Requirements are:
* Torch
  * Required packages (most of them should be part of the default torch install, install missing ones with `luarocks install packageName`): `cudnn`, `nn`, `pl`, `paths`, `image`, `optim`, `cutorch`, `cunn`, `cudnn`, `dpnn`, `display`, `unsup`
* Dataset from [face-generator](https://github.com/aleju/face-generator) (requires LFW and Python to generate)
* NVIDIA GPU with cudnn3 and 4GB or more memory

To train a network:
* `th -ldisplay.start` - This will start `display`, which is used to plot results in the browser
* Open http://localhost:8000/ in your browser (`display` interface)
* Train a pair of G and D with `th train.lua --dataset="/path/to/your/images" --colorSpace="y"` (remove `--colorSpace` to generate RGB images instead of grayscale ones). Manually stop (ctrl+c) this script when you like the results. Might take a few hundred epochs.
* Train R using `th train_r.lua --dataset="/path/to/your/images"` . Manually stop this script after a short while. The shorter it runs, the more "average" the noise vectors recovered by R will be.
* Apply R using `th apply_r.lua --dataset="/path/to/your/images"` .
